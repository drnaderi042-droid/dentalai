# ๐ ุฑุงูููุง ุฑูุน ูุดฺฉู ฺฉูุฏ ุขููุฒุด

## โ๏ธ ูุดฺฉูุงุช ุดูุงุณุง ุดุฏู

1. **CPU ููุท 50% ุฏุฑฺฏุฑ ุงุณุช** - DataLoader bottleneck
2. **Memory ฺฉุงูู ุฏุฑฺฏุฑ ุดุฏู** - prefetch_factor ุง num_workers ุฒุงุฏ ุงุณุช
3. **ุจูููโุณุงุฒโูุง ุงุนูุงู ูุดุฏู** - torch.compile ู channels_last ูุนุงู ูุณุช
4. **Epoch ุงูู ุฎู ฺฉูุฏ** (~30 ุฏููู) - ุจุฏูู ุจูููโุณุงุฒ

---

## โ ุฑุงูฺฉุงุฑูุง ุงุนูุงู ุดุฏู

### 1. ุงูุฒุงุด num_workers (4 โ 8)
- **ูุฏู**: ุงุณุชูุงุฏู ุจูุชุฑ ุงุฒ CPU
- **ูุชุฌู**: CPU utilization ุจุดุชุฑ ูโุดูุฏ

### 2. ฺฉุงูุด prefetch_factor (2 โ 1)
- **ูุฏู**: ุตุฑููโุฌู ุฏุฑ memory
- **ูุชุฌู**: Memory ฺฉูุชุฑ ุงุณุชูุงุฏู ูโุดูุฏ

### 3. ูุนุงู ฺฉุฑุฏู ุจูููโุณุงุฒโูุง
- **torch.compile**: 30-50% ุงูุฒุงุด ุณุฑุนุช
- **channels_last**: 10-20% ุงูุฒุงุด ุณุฑุนุช
- **Early Stopping**: ุตุฑููโุฌู ุฏุฑ ุฒูุงู

### 4. ฺฉุงูุด batch_size (4 โ 2)
- **ูุฏู**: ุตุฑููโุฌู ุฏุฑ memory
- **ูุชุฌู**: Memory ฺฉูุชุฑ ุงุณุชูุงุฏู ูโุดูุฏ

---

## ๐ ุชูุธูุงุช ุฌุฏุฏ

```bash
--batch_size 2                    # ฺฉุงูุด ุงุฒ 4 ุจู 2
--num_workers 8                    # ุงูุฒุงุด ุงุฒ 4 ุจู 8
--prefetch_factor 1               # ฺฉุงูุด ุงุฒ 2 ุจู 1
--use_compile                      # ูุนุงู ฺฉุฑุฏู
--channels_last                    # ูุนุงู ฺฉุฑุฏู
--early_stopping                   # ูุนุงู ฺฉุฑุฏู
--save_frequency 5                 # ฺฉุงูุด checkpoint frequency
```

---

## ๐ ูุชุงุฌ ุงูุชุธุงุฑ

### ูุจู ุงุฒ ุจูููโุณุงุฒ:
- Epoch ุงูู: ~30 ุฏููู
- CPU: 50%
- Memory: ฺฉุงูู ุฏุฑฺฏุฑ
- ุจุฏูู ุจูููโุณุงุฒ

### ุจุนุฏ ุงุฒ ุจูููโุณุงุฒ:
- Epoch ุงูู: ~10-15 ุฏููู (ุจุง compilation)
- Epochโูุง ุจุนุฏ: ~5-8 ุฏููู
- CPU: 70-80% (ุจุง num_workers=8)
- Memory: ฺฉูุชุฑ ุฏุฑฺฏุฑ (ุจุง prefetch_factor=1)
- ุจุง ุจูููโุณุงุฒโูุง: 40-60% ุณุฑุนโุชุฑ

---

## ๐ง ุงฺฏุฑ ูููุฒ ฺฉูุฏ ุงุณุช

### ฺฏุฒูู 1: ุงูุฒุงุด ุจุดุชุฑ num_workers
```bash
--num_workers 12  # ุงฺฏุฑ CPU cores ฺฉุงู ุฏุงุฑุฏ
```

### ฺฏุฒูู 2: ฺฉุงูุด prefetch_factor
```bash
# ุฏุฑ train_1024x1024.py ุฎุท 452 ุฑุง ุชุบุฑ ุฏูุฏ:
prefetch_factor = 1  # ุงุฒ 2 ุจู 1
```

### ฺฏุฒูู 3: ุบุฑูุนุงู ฺฉุฑุฏู persistent_workers
```python
# ุฏุฑ dataset.py ุฎุท 285:
persistent_workers=False  # ุงฺฏุฑ memory ูุดฺฉู ุฏุงุฑุฏ
```

### ฺฏุฒูู 4: ฺฉุงูุด augmentation
```python
# ุฏุฑ dataset.py augmentation ุฑุง ฺฉุงูุด ุฏูุฏ
# ุง ุฏุฑ train_1024x1024.py augmentation ุฑุง ุบุฑูุนุงู ฺฉูุฏ
```

---

## ๐ก ูฺฉุงุช ููู

1. **ุงููู epoch ฺฉูุฏุชุฑ ุงุณุช**: ุจู ุฏูู compilation ุฏุฑ torch.compile
2. **num_workers**: ุจุงุฏ ฺฉูุชุฑ ุงุฒ ุชุนุฏุงุฏ CPU cores ุจุงุดุฏ
3. **prefetch_factor**: ูุฑฺู ฺฉูุชุฑุ memory ฺฉูุชุฑ ุงุณุชูุงุฏู ูโุดูุฏ
4. **Memory**: ุงฺฏุฑ ูููุฒ ฺฉุงูู ุงุณุชุ num_workers ุฑุง ฺฉุงูุด ุฏูุฏ

---

## ๐ฏ ุฏุณุชูุฑ ููุง

```bash
python train_1024x1024.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 1024 1024 \
    --batch_size 2 \
    --gradient_accumulation_steps 4 \
    --epochs 200 \
    --lr 3e-4 \
    --warmup_epochs 10 \
    --mixed_precision \
    --use_ema \
    --multi_gpu \
    --num_workers 8 \
    --use_compile \
    --channels_last \
    --early_stopping \
    --patience 20 \
    --save_frequency 5
```

ุง ุงุณุชูุงุฏู ุงุฒ script ุจููู ุดุฏู:
```bash
train_1024x1024.bat
```

---

**ุชุงุฑุฎ**: 2024-11-01  
**ูุถุนุช**: โ ุจูููโุณุงุฒโูุง ุงุนูุงู ุดุฏ
















