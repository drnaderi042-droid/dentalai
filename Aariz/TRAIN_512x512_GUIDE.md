# ๐ฏ ุฑุงูููุง Training ุจุง Image Size 512ร512

## ๐ ฺุฑุง 512ร512ุ

- โ **ุฏูุช ุจุงูุงุชุฑ**: Resolution ุจุดุชุฑ = ุฌุฒุฆุงุช ุจุดุชุฑ
- โ **ูุชุงุฌ ุจูุชุฑ**: ูุนูููุงู 3-7% ุจูุจูุฏ SDR
- โ๏ธ **ูุงุฒ ุจู VRAM ุจุดุชุฑ**: ุญุฏุงูู 8GB GPU
- โ๏ธ **ุฒูุงู ุจุดุชุฑ**: ~2x ุฒูุงู training ูุณุจุช ุจู 256ร256

---

## ๐ง ุชูุธูุงุช ูพุดููุงุฏ

### ุจุฑุง RTX 3070 Ti (8GB VRAM)

```bash
python train2.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 512 512 \
    --batch_size 8 \
    --lr 5e-4 \
    --warmup_epochs 5 \
    --epochs 100 \
    --loss adaptive_wing \
    --mixed_precision
```

**ูพุงุฑุงูุชุฑูุง ฺฉูุฏ:**
- `--image_size 512 512`: ุณุงุฒ ุฌุฏุฏ โ
- `--batch_size 8`: ฺฉุงูุด ุงุฒ 16 (ุจู ุฎุงุทุฑ VRAM)
- `--mixed_precision`: ุจุฑุง ฺฉุงูุด VRAM ุงุณุชูุงุฏู

---

## ๐ฏ ุฏู ุงุณุชุฑุงุชฺ

### ุงุณุชุฑุงุชฺ 1: Fine-tuning ุงุฒ Checkpoint ูุนู โญ (ูพุดููุงุฏ)

**ูุฒุงุง:**
- โ ุณุฑุนโุชุฑ (50 epoch ฺฉุงู ุงุณุช)
- โ ุงุฒ ุงุฏฺฏุฑ ูุจู ุงุณุชูุงุฏู ูโฺฉูุฏ
- โ ฺฉูโุฑุณฺฉโุชุฑ

**ุฏุณุชูุฑ:**
```bash
python train2.py \
    --resume checkpoints/checkpoint_best.pth \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 512 512 \
    --batch_size 8 \
    --lr 1e-5 \
    --warmup_epochs 3 \
    --epochs 50 \
    --loss adaptive_wing \
    --mixed_precision
```

**ูฺฉุงุช:**
- `--lr 1e-5`: Learning rate ูพุงู (fine-tuning)
- `--epochs 50`: ฺฉุงู ุงุณุช ุจุฑุง fine-tuning

**ุฒูุงู**: 4-6 ุณุงุนุช (ุจุง RTX 3070 Ti)

---

### ุงุณุชุฑุงุชฺ 2: ุขููุฒุด ุงุฒ ุงูู

**ุฒูุงู**: 8-12 ุณุงุนุช (100 epochs)

**ุฏุณุชูุฑ:**
```bash
python train2.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 512 512 \
    --batch_size 8 \
    --lr 5e-4 \
    --warmup_epochs 5 \
    --epochs 100 \
    --loss adaptive_wing \
    --mixed_precision
```

---

## ๐ ุงุณุชูุงุฏู ุงุฒ Batch File (ุณุงุฏูโุชุฑู)

```batch
Aariz\train_512x512.bat
```

ุงู batch file ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ:
- ุจุฑุฑุณ ูโฺฉูุฏ checkpoint ููุฌูุฏ ุงุณุช ุง ูู
- ุงฺฏุฑ ููุฌูุฏ ุจุงุดุฏ: ฺฏุฒูู fine-tuning ูโุฏูุฏ
- ุงฺฏุฑ ูุจุงุดุฏ: ุงุฒ ุงูู ุดุฑูุน ูโฺฉูุฏ

---

## โ๏ธ ุชูุธูุงุช ูพุดุฑูุชู

### ุงฺฏุฑ Out of Memory Error ฺฏุฑูุชุฏ:

**ฺฏุฒูู 1: ฺฉุงูุด Batch Size**
```bash
--batch_size 6  # ุง 4
```

**ฺฏุฒูู 2: ุงุณุชูุงุฏู ุงุฒ Gradient Accumulation**
(ูุงุฒ ุจู ุชุบุฑ ฺฉุฏ train2.py)

**ฺฏุฒูู 3: ุงุณุชูุงุฏู ุงุฒ Image Size ฺฉูฺฺฉโุชุฑ**
```bash
--image_size 384 384  # ุชุนุงุฏู ุจู ุฏูุช ู VRAM
```

---

## ๐ ูุชุงุฌ ุงูุชุธุงุฑ

### Fine-tuning (ุงุฒ 256ร256 checkpoint):
- **MRE**: ุงุฒ 1.99mm ุจู **1.5-1.7mm**
- **SDR @ 2mm**: ุงุฒ 65% ุจู **70-75%**
- **ุฒูุงู**: 4-6 ุณุงุนุช

### Training ุงุฒ ุงูู:
- **MRE**: **1.3-1.6mm**
- **SDR @ 2mm**: **72-78%**
- **ุฒูุงู**: 8-12 ุณุงุนุช

---

## ๐ ุฑุตุฏ ฺฉุฑุฏู Training

### Tensorboard:
```bash
tensorboard --logdir logs
```

### ุจุฑุฑุณ Checkpoints:
```bash
# ูุฑ 10 epoch ฺฉ checkpoint ุฐุฎุฑู ูโุดูุฏ
ls checkpoints/

# ูพุฏุง ฺฉุฑุฏู ุจูุชุฑู checkpoint:
python find_best_checkpoint.py checkpoints/
```

---

## โ๏ธ ูฺฉุงุช ููู

1. **VRAM**: ุญุฏุงูู 8GB ูุงุฒู ุงุณุช
2. **Heatmap Sigma**: ุจุงุฏ ูุชูุงุณุจ ุจุง image size ุจุงุดุฏ
   - ุจุฑุง 512ร512: sigma โ 6.0 (2x ุจุดุชุฑ ุงุฒ 256ร256)
3. **Batch Size**: ุจุง 512ร512ุ batch_size=8 ุญุฏุงฺฉุซุฑ ุจุฑุง 8GB VRAM
4. **ุฒูุงู**: ~2x ุฒูุงู ุจุดุชุฑ ูุณุจุช ุจู 256ร256

---

## ๐ ุฏุณุชูุฑุงุช ุณุฑุน

### Fine-tuning (ูพุดููุงุฏ):
```bash
cd Aariz
python train2.py --resume checkpoints/checkpoint_best.pth --dataset_path Aariz --model hrnet --image_size 512 512 --batch_size 8 --lr 1e-5 --warmup_epochs 3 --epochs 50 --loss adaptive_wing --mixed_precision
```

### ุง ุงุณุชูุงุฏู ุงุฒ Batch File:
```batch
Aariz\train_512x512.bat
```

---

## ๐ ูุฑุงุญู ุจุนุฏ

ุจุนุฏ ุงุฒ training:
1. โ ุชุณุช ุฑู validation set
2. โ ููุงุณู ุจุง ูุชุงุฌ ูุจู (256ร256)
3. โ ุงุณุชูุงุฏู ุงุฒ TTA ุจุฑุง ุจูุจูุฏ ุจุดุชุฑ (ุงุฎุชุงุฑ)

---

**ุชุงุฑุฎ**: 2024-11-01
**ูุถุนุช**: โ ุขูุงุฏู ุจุฑุง ุงุณุชูุงุฏู

