# ğŸ”§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Out of Memory (OOM) Ø¨Ø±Ø§ÛŒ 1024x1024

## âš ï¸ Ù…Ø´Ú©Ù„: CUDA out of memory

Ø§Ú¯Ø± Ø¨Ø§ Ø®Ø·Ø§ÛŒ `RuntimeError: CUDA error: out of memory` Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ÛŒØ¯ØŒ Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±Ø§ Ø¯Ù†Ø¨Ø§Ù„ Ú©Ù†ÛŒØ¯.

---

## âœ… Ø±Ø§Ù‡ Ø­Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹

### 1. Ú©Ø§Ù‡Ø´ Batch Size (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ)

```bash
# Batch size Ø±Ø§ Ø§Ø² 2 Ø¨Ù‡ 1 Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
python3 train_1024x1024.py --batch_size 1 --num_workers 2 ...
```

### 2. Ú©Ø§Ù‡Ø´ num_workers

```bash
# num_workers Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
python3 train_1024x1024.py --num_workers 2 ...
```

### 3. ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† pin_memory

```bash
# pin_memory Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯ (Ø§Ú¯Ø± OOM Ø¯Ø± pin memory thread Ø¨ÙˆØ¯)
python3 train_1024x1024.py --pin_memory ...
```

### 4. Ø§ÙØ²Ø§ÛŒØ´ Gradient Accumulation

```bash
# Batch size Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯ Ùˆ gradient accumulation Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯
python3 train_1024x1024.py --batch_size 1 --gradient_accumulation_steps 8 ...
```

---

## ğŸ“Š ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ 1024x1024

### Ø¨Ø±Ø§ÛŒ RTX 3060 (12GB VRAM):

| ØªÙ†Ø¸ÛŒÙ…Ø§Øª | Batch Size | num_workers | Gradient Accum | Effective Batch |
|---------|------------|-------------|----------------|-----------------|
| **Conservative** | 1 | 2 | 8 | 16 |
| **Balanced** â­ | 2 | 4 | 4 | 16 |
| **Aggressive** | 2 | 6 | 4 | 16 |

---

## ğŸ” ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„

### Ù…Ø´Ú©Ù„ 1: OOM Ø¯Ø± Pin Memory Thread

```
RuntimeError: Caught RuntimeError in pin memory thread for device 0.
```

**Ø±Ø§Ù‡ Ø­Ù„:**
```bash
# pin_memory Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
python3 train_1024x1024.py --pin_memory ...
```

ÛŒØ§ Ø¯Ø± Ú©Ø¯:
```python
# Ø¯Ø± dataset.pyØŒ pin_memory=False ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
```

### Ù…Ø´Ú©Ù„ 2: OOM Ø¯Ø± Forward Pass

```
RuntimeError: CUDA out of memory. Tried to allocate X GB
```

**Ø±Ø§Ù‡ Ø­Ù„:**
- Batch size Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
- Gradient accumulation Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯
- Mixed precision Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯ (Ø§Ú¯Ø± Ù†ÛŒØ³Øª)

### Ù…Ø´Ú©Ù„ 3: OOM Ø¯Ø± DataLoader

```
RuntimeError: CUDA error: out of memory (Ø¯Ø± DataLoader)
```

**Ø±Ø§Ù‡ Ø­Ù„:**
- num_workers Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
- prefetch_factor Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
- pin_memory Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯

---

## ğŸ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ 1024x1024

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯):

```bash
python3 train_1024x1024.py \
    --batch_size 2 \
    --num_workers 4 \
    --gradient_accumulation_steps 4 \
    --mixed_precision \
    --image_size 1024 1024
```

**Effective Batch Size:** 16 (2 Ã— 2 GPUs Ã— 4 accumulation)

---

## ğŸ“‰ Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² OOM Ú¯Ø±ÙØªÛŒØ¯

### Ú¯Ø²ÛŒÙ†Ù‡ 1: Batch Size = 1

```bash
python3 train_1024x1024.py \
    --batch_size 1 \
    --gradient_accumulation_steps 8 \
    --num_workers 2
```

**Effective Batch Size:** 16 (1 Ã— 2 GPUs Ã— 8 accumulation)

### Ú¯Ø²ÛŒÙ†Ù‡ 2: Ú©Ø§Ù‡Ø´ Image Size Ù…ÙˆÙ‚Øª

```bash
# Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ 768x768 Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯
python3 train_1024x1024.py --image_size 768 768 --batch_size 4

# Ø³Ù¾Ø³ fine-tune Ø¨Ø§ 1024x1024
python3 train_1024x1024.py --image_size 1024 1024 --batch_size 2 --resume checkpoints_1024x1024/checkpoint_best.pth
```

### Ú¯Ø²ÛŒÙ†Ù‡ 3: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Gradient Checkpointing

```python
# Ø¯Ø± model.pyØŒ gradient checkpointing Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
# (Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ± Ú©Ø¯ Ø¯Ø§Ø±Ø¯)
```

---

## ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Memory

```bash
# Ø¯Ø± terminal Ø¯ÛŒÚ¯Ø±
watch -n 1 nvidia-smi
```

**Ø¨Ø§ÛŒØ¯ Ø¨Ø¨ÛŒÙ†ÛŒØ¯:**
- GPU 0: ~8-10GB VRAM (Ù†Ù‡ 12GB)
- GPU 1: ~8-10GB VRAM (Ù†Ù‡ 12GB)
- Ù‡Ø± Ø¯Ùˆ GPU: Utilization Ù…Ø´Ø§Ø¨Ù‡

---

## âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡

### 1. Clear CUDA Cache

```python
# Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ training
torch.cuda.empty_cache()
```

### 2. Limit Memory Growth

```python
# Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ training
torch.cuda.set_per_process_memory_fraction(0.9)  # 90% of VRAM
```

### 3. Use CPU Offloading (Ø¢Ø®Ø±ÛŒÙ† Ø±Ø§Ù‡)

```python
# Ø¨Ø±Ø§ÛŒ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø§Ø² CPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
# (Ú©Ù†Ø¯ØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ù…Ø§ memory Ú©Ù…ØªØ±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
```

---

## ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø³ØªÙˆØ±Ø§Øª

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Conservative (Ø§Ú¯Ø± OOM Ú¯Ø±ÙØªÛŒØ¯):

```bash
python3 train_1024x1024.py \
    --batch_size 1 \
    --num_workers 2 \
    --gradient_accumulation_steps 8 \
    --mixed_precision \
    --use_ema \
    --multi_gpu
```

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Balanced (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ):

```bash
python3 train_1024x1024.py \
    --batch_size 2 \
    --num_workers 4 \
    --gradient_accumulation_steps 4 \
    --mixed_precision \
    --use_ema \
    --multi_gpu
```

---

## âœ… Ú†Ú©â€ŒÙ„ÛŒØ³Øª

Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹ training:

- [ ] Batch size Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª (1 ÛŒØ§ 2 Ø¨Ø±Ø§ÛŒ 1024x1024)
- [ ] num_workers Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ (2-4)
- [ ] Mixed precision ÙØ¹Ø§Ù„ Ø§Ø³Øª
- [ ] pin_memory ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª (Ø§Ú¯Ø± Ù…Ø´Ú©Ù„ Ø¯Ø§Ø´ØªÛŒØ¯)
- [ ] Gradient accumulation ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡
- [ ] Ù‡Ø± Ø¯Ùˆ GPU Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù‡Ø³ØªÙ†Ø¯

---

**ØªØ§Ø±ÛŒØ®**: 2024-11-01  
**ÙˆØ¶Ø¹ÛŒØª**: âœ… Ø±Ø§Ù‡ Ø­Ù„â€ŒÙ‡Ø§ÛŒ OOM Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯

















