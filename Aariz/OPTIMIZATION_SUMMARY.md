# ุฎูุงุตู ุจูููโุณุงุฒโูุง ุจุฑุง ฺฉุงูุด GPU Memory ู ุงูุฒุงุด ุณุฑุนุช

## ๐ง ุชุบุฑุงุช ุงุนูุงู ุดุฏู

### 1. โ Gradient Accumulation ุงุถุงูู ุดุฏ

**ูุจู:**
- Batch size: 4
- ูุฑ batch ูุณุชููุงู update ูโุดุฏ
- GPU memory: ~4500 MB

**ุจุนุฏ:**
- Batch size: 2 (ฺฉุงูุด 50%)
- Gradient accumulation: 2 steps
- Effective batch size: 2 ร 2 = 4 (ููุงู ูุจู)
- GPU memory: ~3000-3500 MB (ฺฉุงูุด ~30%)

### 2. โ ุงูุฒุงุด num_workers

**ูุจู:**
- num_workers: 4

**ุจุนุฏ:**
- num_workers: 6 (ุงูุฒุงุด 50%)
- ุณุฑุนุช data loading ุจุดุชุฑ ูโุดูุฏ
- GPU ฺฉูุชุฑ idle ูโูุงูุฏ

### 3. โ Mixed Precision (FP16) - ูุนุงู

- ฺฉุงูุด ~50% ุฏุฑ GPU memory
- ุงูุฒุงุด ~30-40% ุฏุฑ ุณุฑุนุช training
- ุฏูุช ุชูุฑุจุงู ฺฉุณุงู

### 4. โ ููุท 12 ููุฏูุงุฑฺฉ ูุดฺฉูโุฏุงุฑ

- ฺฉุงูุด ~40% ุฏุฑ computation
- ุณุฑุนุช training ุจุดุชุฑ

## ๐ ููุงุณู ุชูุธูุงุช

| ูพุงุฑุงูุชุฑ | ูุจู | ุจุนุฏ | ุชุบุฑ |
|---------|-----|-----|-------|
| **Batch Size** | 4 | 2 | โ 50% |
| **Gradient Accum** | 1 | 2 | โ 100% |
| **Effective Batch** | 4 | 4 | = |
| **num_workers** | 4 | 6 | โ 50% |
| **GPU Memory** | ~4500 MB | ~3000 MB | โ 30% |
| **Speed** | Baseline | +20-30% | โ |

## โก ูุฒุงุง

1. **ฺฉุงูุด GPU Memory:** ุงุฒ ~4500MB ุจู ~3000MB (ฺฉุงูุด 30%)
2. **ุงูุฒุงุด ุณุฑุนุช:** ุจุง num_workers ุจุดุชุฑ ู FP16
3. **ุญูุธ ฺฉูุช:** Effective batch size ููุงู ุงุณุช (4)
4. **ูพุงุฏุงุฑ:** Gradient accumulation ุจุงุนุซ training ูพุงุฏุงุฑุชุฑ ูโุดูุฏ

## ๐ ุฏุณุชูุฑ ุงุฌุฑุง

```bash
cd Aariz
.\train_768_weighted_loss.bat
```

ุง:

```bash
cd Aariz
python train2.py \
    --resume checkpoint_best_768.pth \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 768 768 \
    --batch_size 2 \
    --gradient_accumulation_steps 2 \
    --lr 1e-6 \
    --warmup_epochs 2 \
    --epochs 60 \
    --loss adaptive_wing \
    --mixed_precision \
    --num_workers 6
```

## โฑ๏ธ ุฒูุงู ุชุฎูู

- ูุจู: ~4 ุณุงุนุช
- ุจุนุฏ: ~2.5-3 ุณุงุนุช (ุจุง ุจูููโุณุงุฒโูุง)
- ุจูุจูุฏ: ~25-35% ุณุฑุนโุชุฑ

## ๐ ูฺฉุงุช ููู

1. **Effective Batch Size:** ููุงู 4 ุจุงู ูุงูุฏู (2 ร 2)
2. **Learning Rate:** ููุงู ุงุณุช (1e-6) - ฺูู effective batch size ุชุบุฑ ูฺฉุฑุฏู
3. **Gradient Accumulation:** ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ handle ูโุดูุฏ
4. **Memory:** ~1500MB freed ุจุฑุง ุงุณุชูุงุฏูโูุง ุฏฺฏุฑ















