# ุฑุงูููุง ฺฉุงูุด ุฎุทุง ููุฏูุงุฑฺฉโูุง ูุดฺฉูโุฏุงุฑ

## ๐ ููุฏูุงุฑฺฉโูุง ุจุง ุจุดุชุฑู ุฎุทุง

ุจุฑ ุงุณุงุณ ุชุญูู ุงูุฌุงู ุดุฏูุ ููุฏูุงุฑฺฉโูุง ุฒุฑ ุจุดุชุฑู ุฎุทุง ุฑุง ุฏุงุฑูุฏ:

| ุฑุชุจู | ููุฏูุงุฑฺฉ | ูุงูฺฏู ุฎุทุง (mm) | ุชูุถุญุงุช |
|------|---------|------------------|----------|
| ๐ฅ | **UMT** | 3.805 | Upper Molar Tip (ููฺฉ ุฏูุฏุงู ุขุณุง ุจุฒุฑฺฏ ุจุงูุง) |
| ๐ฅ | **UPM** | 3.486 | Upper Premolar (ุฏูุฏุงู ุขุณุง ฺฉูฺฺฉ ุจุงูุง) |
| ๐ฅ | **R** | 3.331 | Ramus point (ููุทู ุดุงุฎู ูฺฉ) |
| 4 | **Ar** | 2.645 | Articulare (ููุทู ููุตู ูฺฉ) |
| 5 | **Go** | 2.618 | Gonion (ุฒุงูู ูฺฉ ูพุงู) |
| 6 | **LMT** | 2.545 | Lower Molar Tip (ููฺฉ ุฏูุฏุงู ุขุณุง ุจุฒุฑฺฏ ูพุงู) |

## ๐ฏ ุฑุงูฺฉุงุฑูุง ฺฉุงูุด ุฎุทุง (ุงูููุชโุจูุฏ ุดุฏู)

### 1. โ Weighted Loss (ุณุฑุนโุชุฑู ู ูุคุซุฑุชุฑู)

**ูุฏู:** ุฏุงุฏู ูุฒู ุจุดุชุฑ ุจู ููุฏูุงุฑฺฉโูุง ูุดฺฉูโุฏุงุฑ ุฏุฑ loss function

**ูพุงุฏูโุณุงุฒ:**
```bash
# ุงุฌุฑุง ุงุณฺฉุฑูพุช ุจุฑุง ุงุนูุงู ุชุบุฑุงุช
python apply_weighted_loss_to_train2.py
```

**ุงูุชุธุงุฑุงุช:**
- ฺฉุงูุด 30-40% ุฏุฑ ุฎุทุง ููุฏูุงุฑฺฉโูุง ูุดฺฉูโุฏุงุฑ
- ฺฉุงูุด 15-20% ุฏุฑ MRE ฺฉู

### 2. โ ุงูุฒุงุด Augmentation ุจุฑุง ููุงุทู ูุดฺฉูโุฏุงุฑ

**ุชุบุฑุงุช ุฏุฑ `dataset.py`:**

```python
# ุฏุฑ ุชุงุจุน _get_transformsุ ุจุฑุง training:
if self.augmentation:
    return A.Compose([
        # Rotation ุจุดุชุฑ ุจุฑุง ุฏูุฏุงูโูุง
        A.Rotate(limit=15, p=0.7),  # ุงุฒ 10 ุจู 15 ุฏุฑุฌู
        
        # Contrast ู Brightness ุจุดุชุฑ
        A.RandomBrightnessContrast(
            brightness_limit=0.3,  # ุงุฒ 0.2 ุจู 0.3
            contrast_limit=0.3,
            p=0.7
        ),
        
        # Noise ุจุดุชุฑ
        A.GaussNoise(var_limit=(20, 80), p=0.5),
        
        # Elastic Transform ููโุชุฑ
        A.ElasticTransform(
            alpha=150,  # ุงุฒ 120 ุจู 150
            sigma=150*0.05,
            p=0.4
        ),
        
        A.Resize(height=height, width=width),
        A.Normalize(mean=0.5, std=0.5),
        ToTensorV2(),
    ])
```

### 3. โ Hard Negative Mining

**ุดูุงุณุง ู ุชูุฑฺฉุฒ ุฑู ุชุตุงูุฑ ูุดฺฉูโุฏุงุฑ:**

```python
# ุงุฌุงุฏ ุงุณฺฉุฑูพุช ุจุฑุง ุดูุงุณุง hard samples
def identify_hard_samples(model, val_loader, threshold_mm=2.5):
    """
    ุดูุงุณุง ุชุตุงูุฑ ฺฉู ููุฏูุงุฑฺฉโูุง ูุดฺฉูโุฏุงุฑ ุฎุทุง ุจุงูุง ุฏุงุฑูุฏ
    """
    hard_samples = []
    DIFFICULT_LANDMARKS = ['UMT', 'UPM', 'R', 'Ar', 'Go', 'LMT']
    
    # ... ฺฉุฏ ุดูุงุณุง ...
    
    return hard_samples

# ุณูพุณ ุฏุฑ trainingุ ุงู samples ุฑุง ุจุดุชุฑ ุชฺฉุฑุงุฑ ฺฉูุฏ
```

### 4. โ Fine-tuning ุฑู Subset ูุดฺฉูโุฏุงุฑ

```bash
# Fine-tuning ููุท ุฑู ุชุตุงูุฑ ุจุง ุฎุทุง ุจุงูุง
python train2.py \
    --resume checkpoints/checkpoint_best_768.pth \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 768 768 \
    --batch_size 4 \
    --lr 1e-6 \
    --epochs 20 \
    --loss adaptive_wing \
    --mixed_precision \
    --hard_samples_only
```

### 5. โ Multi-Scale Training

Training ุฏุฑ ฺูุฏ resolution ูุฎุชูู:

```python
# ุฏุฑ training loop
scales = [512, 768, 1024]
scale = random.choice(scales)
image_resized = resize_image(image, scale)
```

### 6. โ ุงูุฒุงุด Resolution

Training ุฏุฑ resolution ุจุงูุงุชุฑ (1024x1024) ุจุฑุง ุฏูุช ุจุดุชุฑ:

```bash
python train_1024x1024.py \
    --resume checkpoints/checkpoint_best_768.pth \
    --dataset_path Aariz \
    --batch_size 2 \
    --lr 1e-6 \
    --epochs 30
```

## ๐ ุจุฑูุงูู ุงุฌุฑุง ูพุดููุงุฏ

### ูุฑุญูู 1: ุงุนูุงู Weighted Loss (1-2 ุณุงุนุช)
```bash
# 1. ุงุนูุงู ุชุบุฑุงุช
python apply_weighted_loss_to_train2.py

# 2. Fine-tuning ุจุง weighted loss
python train2.py \
    --resume checkpoints/checkpoint_best_768.pth \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 768 768 \
    --batch_size 4 \
    --lr 1e-6 \
    --warmup_epochs 2 \
    --epochs 20 \
    --loss adaptive_wing \
    --mixed_precision

# 3. ุชุณุช ูุชุงุฌ
python test_768_validation_full.py
```

### ูุฑุญูู 2: ุจูุจูุฏ Augmentation (30 ุฏููู)
- ูุฑุงุด `dataset.py` ู ุงูุฒุงุด augmentation
- Retrain ุจุง augmentation ุฌุฏุฏ

### ูุฑุญูู 3: Hard Negative Mining (2-3 ุณุงุนุช)
- ุดูุงุณุง hard samples
- Fine-tuning ุฑู ุขูโูุง

## ๐ ุงูุชุธุงุฑุงุช ุงุฒ ุจูุจูุฏ

ุจุนุฏ ุงุฒ ุงุนูุงู **Weighted Loss + Augmentation**:

| ููุฏูุงุฑฺฉ | ุฎุทุง ูุนู | ุฎุทุง ุงูุชุธุงุฑ | ุจูุจูุฏ |
|---------|-----------|--------------|-------|
| UMT | 3.805 mm | ~2.3 mm | 40% โ |
| UPM | 3.486 mm | ~2.1 mm | 40% โ |
| R | 3.331 mm | ~2.2 mm | 34% โ |
| Ar | 2.645 mm | ~1.8 mm | 32% โ |
| Go | 2.618 mm | ~1.8 mm | 31% โ |
| **MRE ฺฉู** | 1.575 mm | **~1.25 mm** | **20% โ** |
| **SDR @ 2mm** | 76.21% | **~85%** | **+9%** |

## โ๏ธ ูฺฉุงุช ููู

1. **Backup ูุจู ุงุฒ ุชุบุฑุงุช:** ููุดู backup ุจฺฏุฑุฏ
2. **Validation Monitoring:** ููุดู validation loss ุฑุง monitor ฺฉูุฏ
3. **Gradual Increase:** ุจู ุชุฏุฑุฌ ูุฒูโูุง ุฑุง ุงูุฒุงุด ุฏูุฏ
4. **A/B Testing:** ูุชุงุฌ ุฑุง ุจุง ู ุจุฏูู ุชุบุฑุงุช ููุงุณู ฺฉูุฏ
5. **Overfitting:** ูุฑุงูุจ overfitting ุจุงุดุฏ - ุงฺฏุฑ validation loss ุงูุฒุงุด ุงูุชุ ูุฒูโูุง ุฑุง ฺฉุงูุด ุฏูุฏ

## ๐ Troubleshooting

### ุงฺฏุฑ validation loss ุงูุฒุงุด ุงูุช:
- ูุฒูโูุง ุฑุง ฺฉุงูุด ุฏูุฏ (ูุซูุงู ุงุฒ 2.5 ุจู 2.0)
- Learning rate ุฑุง ฺฉุงูุด ุฏูุฏ
- Epochs ุฑุง ฺฉุงูุด ุฏูุฏ

### ุงฺฏุฑ ุจูุจูุฏ ูุดุงูุฏู ูุดุฏ:
- ุจุฑุฑุณ ฺฉูุฏ ฺฉู weighted loss ุฏุฑุณุช ุงุนูุงู ุดุฏู
- ุจุฑุฑุณ ฺฉูุฏ ฺฉู augmentation ุงุนูุงู ูโุดูุฏ
- ุชุนุฏุงุฏ epochs ุฑุง ุงูุฒุงุด ุฏูุฏ

## ๐ ุฎูุงุตู

**ุณุฑุนโุชุฑู ุฑุงู:** ุงุนูุงู Weighted Loss (1-2 ุณุงุนุช ฺฉุงุฑ)
**ูุคุซุฑุชุฑู ุฑุงู:** Weighted Loss + Augmentation + Hard Negative Mining
**ุจูุชุฑู ูุชุฌู:** Multi-Scale + High Resolution + Ensemble

ุดุฑูุน ฺฉูุฏ ุจุง **Weighted Loss** ฺฉู ุณุฑุนโุชุฑู ู ูุคุซุฑุชุฑู ุงุณุช!















