# ๐ง ุฑุงูููุง ุฑูุน ูุดฺฉู Multi-GPU (ุงุณุชูุงุฏู ุงุฒ ูุฑ ุฏู GPU)

## โ๏ธ ูุดฺฉู: ููุท ฺฉ GPU ุงุณุชูุงุฏู ูโุดูุฏ

ุงฺฏุฑ ููุท GPU 0 ุงุณุชูุงุฏู ูโุดูุฏ ู GPU 1 ุฎุงู ุงุณุชุ ุงุฒ ุงู ุฑุงูููุง ุงุณุชูุงุฏู ฺฉูุฏ.

---

## โ ุฑุงู ุญู: ุงุณุชูุงุฏู ุงุฒ DistributedDataParallel (DDP)

**DDP ุจูุชุฑ ุงุฒ DataParallel ุงุณุช** ู ูุทูุฆูุงู ุงุฒ ูุฑ ุฏู GPU ุงุณุชูุงุฏู ูโฺฉูุฏ.

### ุฑูุด 1: ุงุณุชูุงุฏู ุงุฒ torchrun (ุชูุตู ูโุดูุฏ) โญ

```bash
# ุฏุฑ WSL2
cd /mnt/c/Users/Salah/Downloads/Compressed/Dentalai/main\ -\ Copy/Aariz

# ุฏุงุฏู permission
chmod +x train_1024x1024_ddp.sh

# ุงุฌุฑุง
./train_1024x1024_ddp.sh
```

ุง ุฏุณุชูุฑ ูุณุชูู:

```bash
torchrun --nproc_per_node=2 train_1024x1024.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 1024 1024 \
    --batch_size 2 \
    --gradient_accumulation_steps 4 \
    --epochs 200 \
    --lr 3e-4 \
    --warmup_epochs 10 \
    --mixed_precision \
    --use_ema \
    --use_ddp \
    --num_workers 4
```

### ุฑูุด 2: ุงุณุชูุงุฏู ุงุฒ DataParallel (ุงฺฏุฑ DDP ฺฉุงุฑ ูฺฉุฑุฏ)

```bash
python3 train_1024x1024.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 1024 1024 \
    --batch_size 2 \
    --gradient_accumulation_steps 4 \
    --epochs 200 \
    --lr 3e-4 \
    --warmup_epochs 10 \
    --mixed_precision \
    --use_ema \
    --multi_gpu \
    --num_workers 4
```

---

## ๐ ุจุฑุฑุณ ุงุณุชูุงุฏู ุงุฒ GPU

ุฏุฑ terminal ุฏฺฏุฑ:

```bash
watch -n 1 nvidia-smi
```

**ุจุง DDP ุจุงุฏ ุจุจูุฏ:**
- GPU 0: ~45-55% utilization, ~6-8GB VRAM
- GPU 1: ~45-55% utilization, ~6-8GB VRAM
- ูุฑ ุฏู GPU: Memory ู Utilization ูุดุงุจู

---

## ๐ ููุงุณู DataParallel vs DDP

| ูฺฺฏ | DataParallel | DDP (DistributedDataParallel) |
|-------|--------------|-------------------------------|
| ุงุณุชูุงุฏู ุงุฒ ูุฑ ุฏู GPU | โ๏ธ ููฺฉู ุงุณุช ูุดฺฉู ุฏุงุดุชู ุจุงุดุฏ | โ ูุทูุฆู |
| Performance | โญโญโญ | โญโญโญโญ |
| ูพฺุฏฺฏ | ุณุงุฏู | ูุชูุณุท |
| WSL2 | โ๏ธ ูุดฺฉูุงุช ุฏุงุฑุฏ | โ ุจูุชุฑ ฺฉุงุฑ ูโฺฉูุฏ |

---

## ๐ฏ ุชูุตู

**ุจุฑุง WSL2: ุงุฒ DDP ุงุณุชูุงุฏู ฺฉูุฏ!**

```bash
./train_1024x1024_ddp.sh
```

ุงู ูุทูุฆูุงู ุงุฒ ูุฑ ุฏู GPU ุงุณุชูุงุฏู ูโฺฉูุฏ.

---

## ๐ ุนุจโุงุจ

### ูุดฺฉู 1: torchrun ูพุฏุง ููโุดูุฏ

```bash
# ูุตุจ PyTorch ุจุง CUDA
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### ูุดฺฉู 2: DDP ุฎุทุง ูโุฏูุฏ

```bash
# ุงุณุชูุงุฏู ุงุฒ DataParallel ุจู ุฌุง DDP
python3 train_1024x1024.py --multi_gpu --num_workers 4 ...
```

### ูุดฺฉู 3: ูููุฒ ููุท ฺฉ GPU ุงุณุชูุงุฏู ูโุดูุฏ

```bash
# ุจุฑุฑุณ ุชุนุฏุงุฏ GPU
python3 -c "import torch; print('GPUs:', torch.cuda.device_count())"

# ุจุงุฏ 2 ุจุงุดุฏ
```

---

**ุชุงุฑุฎ**: 2024-11-01  
**ูุถุนุช**: โ ุฑุงู ุญู DDP ุงุถุงูู ุดุฏ

















