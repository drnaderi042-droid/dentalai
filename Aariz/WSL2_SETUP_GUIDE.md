# ğŸ§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² WSL2 (Ubuntu 22) Ø¨Ø±Ø§ÛŒ Training 1024x1024

## Ú†Ø±Ø§ WSL2ØŸ

- âœ… **DataParallel Ø¨Ù‡ØªØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯**: Ø¯Ø± Linux/WSL2ØŒ DataParallel Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ± Ø§Ø³Øª
- âœ… **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² Multi-GPU**: Ù…Ø´Ú©Ù„Ø§Øª Windows Ø­Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
- âœ… **Performance Ø¨Ù‡ØªØ±**: Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 10-15% Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø² Windows
- âœ… **Ú©Ù…ØªØ± Ù…Ø´Ú©Ù„**: Ù…Ø´Ú©Ù„Ø§Øª multiprocessing Ùˆ DataParallel Ú©Ù…ØªØ± Ø§Ø³Øª

---

## ğŸ“‹ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

### 1. Ù†ØµØ¨ WSL2 Ø¨Ø§ Ubuntu 22.04

Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù†ØµØ¨ Ù†Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯:

```powershell
# Ø¯Ø± PowerShell Ø¨Ø§ Administrator
wsl --install -d Ubuntu-22.04
```

ÛŒØ§ Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ù†ØµØ¨ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯:

```powershell
wsl --set-default-version 2
wsl --install -d Ubuntu-22.04
```

### 2. Ù†ØµØ¨ CUDA Toolkit Ø¨Ø±Ø§ÛŒ WSL2

**Ù…Ù‡Ù…**: Ø¨Ø§ÛŒØ¯ CUDA Toolkit Ø¨Ø±Ø§ÛŒ WSL2 Ù†ØµØ¨ Ø´ÙˆØ¯ (Ù†Ù‡ Windows)

```bash
# Ø¯Ø± Ubuntu WSL2
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb
sudo dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb
sudo cp /var/cuda-repo-wsl-ubuntu-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-4
```

### 3. Ù†ØµØ¨ PyTorch Ø¨Ø§ CUDA Ø¯Ø± WSL2

```bash
# Ø¯Ø± Ubuntu WSL2
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

ÛŒØ§ Ø§Ú¯Ø± Ø§Ø² requirements.txt Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯:

```bash
pip3 install -r requirements.txt
```

### 4. Ø¨Ø±Ø±Ø³ÛŒ GPU Ø¯Ø± WSL2

```bash
# Ø¨Ø±Ø±Ø³ÛŒ CUDA
nvidia-smi

# Ø¨Ø±Ø±Ø³ÛŒ PyTorch
python3 -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('GPU count:', torch.cuda.device_count()); [print(f'GPU {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]"
```

---

## ğŸš€ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª

### Ø±ÙˆØ´ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Shell Script (ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)

```bash
# Ø¯Ø± Ubuntu WSL2
cd /mnt/c/Users/Salah/Downloads/Compressed/Dentalai/main\ -\ Copy/Aariz

# Ø¯Ø§Ø¯Ù† permission Ø§Ø¬Ø±Ø§
chmod +x train_1024x1024_wsl.sh

# Ø§Ø¬Ø±Ø§
./train_1024x1024_wsl.sh
```

### Ø±ÙˆØ´ 2: Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Python

```bash
# Ø¯Ø± Ubuntu WSL2
cd /mnt/c/Users/Salah/Downloads/Compressed/Dentalai/main\ -\ Copy/Aariz

python3 train_1024x1024.py \
    --dataset_path Aariz \
    --model hrnet \
    --image_size 1024 1024 \
    --batch_size 4 \
    --gradient_accumulation_steps 4 \
    --epochs 200 \
    --lr 3e-4 \
    --warmup_epochs 10 \
    --mixed_precision \
    --use_ema \
    --multi_gpu
```

---

## ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ WSL2

### 1. Ø§ÙØ²Ø§ÛŒØ´ num_workers (Ø¯Ø± Linux Ø¨Ù‡ØªØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯)

```bash
--num_workers 8  # ÛŒØ§ Ø¨ÛŒØ´ØªØ± (Ø¯Ø± Windows Ù…Ø´Ú©Ù„ Ø¯Ø§Ø´Øª)
```

### 2. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² DistributedDataParallel (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø¨Ø±Ø§ÛŒ performance Ø¨Ù‡ØªØ±)

Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² DDP Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø¨Ù‡ØªØ± Ø§Ø² DataParallel):

```bash
# Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ± Ú©Ø¯ Ø¯Ø§Ø±Ø¯ - Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

---

## ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GPU

Ø¯Ø± terminal Ø¯ÛŒÚ¯Ø± (Ø¯Ø± WSL2 ÛŒØ§ Windows):

```bash
# Ø¯Ø± WSL2
watch -n 1 nvidia-smi

# ÛŒØ§ Ø¯Ø± Windows PowerShell
nvidia-smi -l 1
```

**Ø¨Ø§ÛŒØ¯ Ø¨Ø¨ÛŒÙ†ÛŒØ¯:**
- GPU 0: Utilization ~45-55%
- GPU 1: Utilization ~45-55%
- Ù‡Ø± Ø¯Ùˆ GPU: Memory usage Ù…Ø´Ø§Ø¨Ù‡ (~6-8GB Ù‡Ø± Ú©Ø¯Ø§Ù…)

---

## âš ï¸ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

### 1. Path Ø¯Ø± WSL2

ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Windows Ø¯Ø± `/mnt/c/...` Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ù‡Ø³ØªÙ†Ø¯:

```bash
# Ù…Ø«Ø§Ù„
cd /mnt/c/Users/Salah/Downloads/Compressed/Dentalai/main\ -\ Copy/Aariz
```

### 2. Performance

- WSL2 Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 10-15% Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø² Windows Ø§Ø³Øª
- DataParallel Ø¨Ù‡ØªØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- Ú©Ù…ØªØ± Ù…Ø´Ú©Ù„ multiprocessing

### 3. File Permissions

Ø§Ú¯Ø± Ù…Ø´Ú©Ù„ permission Ø¯Ø§Ø´ØªÛŒØ¯:

```bash
chmod +x train_1024x1024_wsl.sh
```

---

## ğŸ› Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Ù…Ø´Ú©Ù„ 1: CUDA not found Ø¯Ø± WSL2

```bash
# Ø¨Ø±Ø±Ø³ÛŒ CUDA
nvidia-smi

# Ø§Ú¯Ø± Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ CUDA Toolkit Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯
```

### Ù…Ø´Ú©Ù„ 2: PyTorch CUDA not available

```bash
# Ø¨Ø±Ø±Ø³ÛŒ PyTorch
python3 -c "import torch; print(torch.cuda.is_available())"

# Ø§Ú¯Ø± False Ø¨ÙˆØ¯ØŒ PyTorch Ø±Ø§ Ø¨Ø§ CUDA Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Ù…Ø´Ú©Ù„ 3: ÙÙ‚Ø· ÛŒÚ© GPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯

```bash
# Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ GPU
python3 -c "import torch; print(torch.cuda.device_count())"

# Ø¨Ø§ÛŒØ¯ 2 Ø¨Ø§Ø´Ø¯
```

---

## ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø³ØªÙˆØ±Ø§Øª

```bash
# 1. ÙˆØ±ÙˆØ¯ Ø¨Ù‡ WSL2
wsl

# 2. Ø±ÙØªÙ† Ø¨Ù‡ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
cd /mnt/c/Users/Salah/Downloads/Compressed/Dentalai/main\ -\ Copy/Aariz

# 3. Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª
chmod +x train_1024x1024_wsl.sh
./train_1024x1024_wsl.sh

# 4. Ø¨Ø±Ø±Ø³ÛŒ GPU (Ø¯Ø± terminal Ø¯ÛŒÚ¯Ø±)
watch -n 1 nvidia-smi
```

---

## âœ… Ù…Ø²Ø§ÛŒØ§ÛŒ WSL2

| ÙˆÛŒÚ˜Ú¯ÛŒ | Windows | WSL2 |
|-------|---------|------|
| DataParallel | âš ï¸ Ù…Ø´Ú©Ù„Ø§Øª Ø¯Ø§Ø±Ø¯ | âœ… Ø¨Ù‡ØªØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ |
| Multi-GPU | âš ï¸ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø´Ú©Ù„ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ | âœ… Ø¨Ù‡ÛŒÙ†Ù‡ |
| Performance | â­â­â­ | â­â­â­â­ |
| Multiprocessing | âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ø±Ø¯ | âœ… Ø¨Ù‡ØªØ± |
| num_workers | Ù…Ø­Ø¯ÙˆØ¯ (0-2) | Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨ÛŒØ´ØªØ± Ø¨Ø§Ø´Ø¯ (8+) |

---

**ØªØ§Ø±ÛŒØ®**: 2024-11-01  
**ÙˆØ¶Ø¹ÛŒØª**: âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± WSL2  
**Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„**: Ubuntu 22.04 LTS Ø¯Ø± WSL2

















