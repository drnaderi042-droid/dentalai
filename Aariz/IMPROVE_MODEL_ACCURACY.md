# ğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„ Aariz

## ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ù…Ø¯Ù„

Ø§Ø² Ù†ØªØ§ÛŒØ¬ evaluation:
- **MRE**: 1.67mm (Ø®ÙˆØ¨ Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯)
- **SDR @ 2mm**: 71.86% (Ù‡Ø¯Ù: > 75%)
- **SDR @ 4mm**: 92.85% (Ø®ÙˆØ¨)
- Ø¨Ø±Ø®ÛŒ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ Ø®Ø·Ø§ÛŒ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù†Ø¯ (ØªØ§ 3mm)

## ğŸ” ØªØ­Ù„ÛŒÙ„ Ù…Ø´Ú©Ù„

Ø§Ú¯Ø± Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ø§Ø¯Ø±Ø³Øª Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¯Ù„Ø§ÛŒÙ„ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:

1. **Ù…Ø¯Ù„ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù†Ø¯ÛŒØ¯Ù‡** - Ù†ÛŒØ§Ø² Ø¨Ù‡ epochs Ø¨ÛŒØ´ØªØ±
2. **Learning rate Ù†Ø§Ù…Ù†Ø§Ø³Ø¨** - Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§ ÛŒØ§ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø§Ø´Ø¯
3. **Data augmentation Ù†Ø§Ú©Ø§ÙÛŒ ÛŒØ§ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯**
4. **Loss function Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø§Ø±Ø¯**
5. **Checkpoint Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ÛŒØ³Øª**

---

## ğŸš€ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯

### Ø±Ø§Ù‡â€ŒØ­Ù„ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Checkpoint Ø¨Ù‡ØªØ±

#### Ø¨Ø±Ø±Ø³ÛŒ ØªÙ…Ø§Ù… checkpoint Ù‡Ø§:

```python
# Ø¨Ø±Ø±Ø³ÛŒ MRE Ù‡Ø± checkpoint
python evaluate.py --checkpoint checkpoints/checkpoint_epoch_50.pth
python evaluate.py --checkpoint checkpoints/checkpoint_epoch_100.pth
python evaluate.py --checkpoint checkpoints/checkpoint_epoch_150.pth
# ... Ùˆ ØºÛŒØ±Ù‡
```

#### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† checkpoint:

```python
# Ø¯Ø± app_aariz.py ÛŒØ§ inference.py
CHECKPOINT_PATH = 'checkpoints/checkpoint_epoch_XXX.pth'  # checkpoint Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† MRE
```

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 2: Fine-tuning Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯

Ø§Ú¯Ø± Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¢Ù† Ø±Ø§ fine-tune Ú©Ù†ÛŒØ¯:

```bash
cd Aariz
python train_optimized.py \
  --model hrnet \
  --resume checkpoints/checkpoint_best.pth \
  --epochs 100 \
  --learning_rate 1e-5 \  # Learning rate Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø¨Ø±Ø§ÛŒ fine-tuning
  --mixed_precision \
  --use_ema \
  --gradient_accumulation_steps 2
```

**Ù…Ø²Ø§ÛŒØ§:**
- Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¯Ù‚Øª
- Ø­ÙØ¸ Ø¯Ø§Ù†Ø´ Ù‚Ø¨Ù„ÛŒ Ù…Ø¯Ù„
- Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø² Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² ØµÙØ±

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 3: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡

#### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ±:

```bash
python train_optimized.py \
  --model hrnet \
  --dataset_path Aariz \
  --epochs 300 \  # Ø¨ÛŒØ´ØªØ± Ø§Ø² 250
  --batch_size 4 \  # Ø§Ú¯Ø± GPU Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ø¯Ø§Ø±Ø¯
  --image_size 512 512 \
  --learning_rate 3e-4 \  # Ú©Ù…ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
  --mixed_precision \
  --use_ema \
  --gradient_accumulation_steps 2 \
  --warmup_epochs 10
```

#### ÛŒØ§ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ±:

```python
# Ø¯Ø± config.py ÛŒØ§ train_optimized.py
config = {
    'model_name': 'hrnet',
    'image_size': (512, 512),
    'batch_size': 4,
    'epochs': 300,
    'learning_rate': 3e-4,
    'weight_decay': 1e-4,
    'heatmap_sigma': 3.5,  # CRITICAL: Ø¨Ø§ÛŒØ¯ 3-4 Ø¨Ø§Ø´Ø¯
    'focal_alpha': 2.0,
    'focal_beta': 4.0,
    'focal_weight': 0.6,  # Ø§ÙØ²Ø§ÛŒØ´ ÙˆØ²Ù† focal loss
    'augmentation': True,
    'rotation_degrees': 3.0,  # Ú©Ø§Ù‡Ø´ rotation Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
    'brightness': 0.05,  # Ú©Ø§Ù‡Ø´ brightness augmentation
    'contrast': 0.05,
    'scheduler': 'cosine',
    'optimizer': 'adamw',
}
```

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 4: Post-Processing Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ØªØ§ÛŒØ¬

Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÛŒÚ© Ù„Ø§ÛŒÙ‡ post-processing Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯:

```python
# Ø¯Ø± app_aariz.py ÛŒØ§ inference.py

def post_process_landmarks(landmarks, image_size):
    """
    Post-processing Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§
    """
    processed = {}
    
    for name, coords in landmarks.items():
        if coords is None:
            processed[name] = None
            continue
        
        x, y = coords['x'], coords['y']
        
        # 1. Ø­Ø°Ù outliers (Ø§Ú¯Ø± Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªØµÙˆÛŒØ± Ø¨Ø§Ø´Ø¯)
        if x < 0 or x > image_size[0] or y < 0 or y > image_size[1]:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² median filtering Ø¨Ø±Ø§ÛŒ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§ÙˆØ±
            processed[name] = smooth_with_neighbors(name, landmarks, image_size)
        else:
            processed[name] = coords
    
    # 2. Smoothing Ø¨Ø±Ø§ÛŒ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· (Ù…Ø«Ù„Ø§Ù‹ Ø¯Ù†Ø¯Ø§Ù†â€ŒÙ‡Ø§)
    processed = smooth_related_landmarks(processed)
    
    return processed

def smooth_with_neighbors(landmark_name, all_landmarks, image_size):
    """Smooth Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§ÙˆØ±"""
    # Ù…Ù†Ø·Ù‚ smoothing Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ
    # ...
    pass
```

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 5: Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´

#### Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª annotations:

```python
# Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ø±Ø±Ø³ÛŒ annotations
python -c "
from dataset import CephalometricDataset
import matplotlib.pyplot as plt

dataset = CephalometricDataset('Aariz', 'train', image_size=(512, 512))
# Ø¨Ø±Ø±Ø³ÛŒ Ú†Ù†Ø¯ Ù†Ù…ÙˆÙ†Ù‡ ØªØµØ§Ø¯ÙÛŒ
for i in range(min(10, len(dataset))):
    img, landmarks = dataset[i]
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ landmarks Ù…Ù†Ø·Ù‚ÛŒ Ù‡Ø³ØªÙ†Ø¯
    print(f'Sample {i}: {len(landmarks)} landmarks')
"
```

#### Ù†Ú©Ø§Øª:
- Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ annotations Ø¯Ø±Ø³Øª Ù‡Ø³ØªÙ†Ø¯
- Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ pixel size Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªØµÙˆÛŒØ± Ø¯Ø±Ø³Øª Ø§Ø³Øª
- Ø§Ú¯Ø± annotation Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ Ø¯Ø§Ø±ÛŒØ¯ (Senior/Junior)ØŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 6: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ensemble

Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§ Ù‡Ù… ØªØ±Ú©ÛŒØ¨ Ú©Ù†ÛŒØ¯:

```python
# ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ Ú†Ù†Ø¯ checkpoint
checkpoints = [
    'checkpoints/checkpoint_best.pth',
    'checkpoints/checkpoint_epoch_200.pth',
    'checkpoints/checkpoint_epoch_250.pth',
]

predictions = []
for ckpt in checkpoints:
    predictor = LandmarkPredictor(ckpt, model_name='hrnet')
    result = predictor.predict(image)
    predictions.append(result['landmarks'])

# Ù…ØªÙˆØ³Ø· Ú¯ÛŒØ±ÛŒ
ensemble_landmarks = {}
for name in predictions[0].keys():
    coords = [p[name] for p in predictions if p[name] is not None]
    if coords:
        ensemble_landmarks[name] = {
            'x': np.mean([c['x'] for c in coords]),
            'y': np.mean([c['y'] for c in coords])
        }
```

---

### Ø±Ø§Ù‡â€ŒØ­Ù„ 7: ØªÙ†Ø¸ÛŒÙ… Heatmap Sigma

`heatmap_sigma` Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ø§Ø³Øª! Ø¨Ø§ÛŒØ¯ 3-4 Ø¨Ø§Ø´Ø¯:

```python
# Ø¯Ø± config.py
heatmap_sigma: float = 3.5  # CRITICAL: Must be 3-4

# Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ 1.0):
# - Heatmaps Ø®ÛŒÙ„ÛŒ ØªÛŒØ² Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
# - Model ÛŒØ§Ø¯ Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
# - Ù†ØªØ§ÛŒØ¬ Ø¨Ø¯ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
```

---

## ğŸ“‹ Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ø¨Ù‡Ø¨ÙˆØ¯

Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹ Ø¨Ù‡Ø¨ÙˆØ¯:

- [ ] Ø¨Ø±Ø±Ø³ÛŒ ØªÙ…Ø§Ù… checkpoint Ù‡Ø§ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ†
- [ ] Ø¨Ø±Ø±Ø³ÛŒ TensorBoard logs Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ø±ÙˆÙ†Ø¯ Ø¢Ù…ÙˆØ²Ø´
- [ ] Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª annotations Ø¯Ø± dataset
- [ ] ØªØ³Øª Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ú†Ù†Ø¯ ØªØµÙˆÛŒØ± sample
- [ ] Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ heatmap_sigma = 3.5 Ø§Ø³Øª

Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯:

- [ ] Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `train_optimized.py` (Ù†Ù‡ `train.py`)
- [ ] ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† `--mixed_precision`
- [ ] ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† `--use_ema`
- [ ] ØªÙ†Ø¸ÛŒÙ… `heatmap_sigma = 3.5`
- [ ] Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² learning rate Ù…Ù†Ø§Ø³Ø¨ (3e-4 ØªØ§ 5e-4)
- [ ] Ø¢Ù…ÙˆØ²Ø´ Ø­Ø¯Ø§Ù‚Ù„ 250 epochs (ØªØ±Ø¬ÛŒØ­Ø§Ù‹ 300)

---

## ğŸ¯ Ø§Ù‡Ø¯Ø§Ù Ø¨Ù‡Ø¨ÙˆØ¯

Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø§ÛŒÙ† Ø§Ù‡Ø¯Ø§Ù Ø¨Ø±Ø³ÛŒØ¯:

- âœ… **MRE < 1.5mm** (Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±: 1.67mm)
- âœ… **SDR @ 2mm > 75%** (Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±: 71.86%)
- âœ… **SDR @ 4mm > 95%** (Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±: 92.85% - Ø®ÙˆØ¨ Ø§Ø³Øª)

---

## ğŸ”§ Ø¯Ø³ØªÙˆØ± Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ Fine-tuning

```bash
cd Aariz

# Fine-tuning Ø¨Ø§ learning rate Ù¾Ø§ÛŒÛŒÙ†
python train_optimized.py \
  --model hrnet \
  --resume checkpoints/checkpoint_best.pth \
  --epochs 100 \
  --learning_rate 1e-5 \
  --mixed_precision \
  --use_ema \
  --batch_size 4 \
  --image_size 512 512

# Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± checkpoints/checkpoint_best.pth Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

---

## ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

1. **ØµØ¨Ø± Ú©Ù†ÛŒØ¯**: Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø§Ø³Øª
2. **Monitor Ú©Ù†ÛŒØ¯**: Ø§Ø² TensorBoard Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
3. **Test Ú©Ù†ÛŒØ¯**: Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ø¨Ù‡Ø¨ÙˆØ¯ØŒ Ø±ÙˆÛŒ Ú†Ù†Ø¯ ØªØµÙˆÛŒØ± ØªØ³Øª Ú©Ù†ÛŒØ¯
4. **Save Ú©Ù†ÛŒØ¯**: Ø¨Ù‡ØªØ±ÛŒÙ† checkpoint Ø±Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯
5. **Document Ú©Ù†ÛŒØ¯**: ØªÙ†Ø¸ÛŒÙ…Ø§ØªÛŒ Ú©Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ Ø±Ø§ ÛŒØ§Ø¯Ø¯Ø§Ø´Øª Ú©Ù†ÛŒØ¯

---

## ğŸ†˜ Ø§Ú¯Ø± Ù…Ø´Ú©Ù„ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø´Øª

1. Ø¨Ø±Ø±Ø³ÛŒ logs Ø¯Ø± TensorBoard
2. Ø¨Ø±Ø±Ø³ÛŒ MRE Ù‡Ø± Ù„Ù†Ø¯Ù…Ø§Ø±Ú© Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
3. ØªØ³Øª Ù…Ø¯Ù„ Ø±ÙˆÛŒ ØªØµØ§ÙˆÛŒØ± Ù…Ø®ØªÙ„Ù
4. Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø´Ú©Ù„ Ø§Ø² dataset Ø§Ø³Øª ÛŒØ§ Ø§Ø² Ù…Ø¯Ù„
5. Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¯ÛŒÚ¯Ø± (Ù…Ø«Ù„Ø§Ù‹ ResNet ÛŒØ§ Hourglass)

---

**Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯! ğŸ‰**

