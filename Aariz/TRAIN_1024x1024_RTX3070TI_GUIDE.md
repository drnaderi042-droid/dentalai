# ุฑุงูููุง ุขููุฒุด ุจุง ุณุงุฒ 1024x1024 ุจุฑุง RTX 3070 Ti

## ๐ ุฎูุงุตู

ุงู ุฑุงูููุง ูุญูู ุขููุฒุด ูุฏู ุจุง ุฏุชุงุณุช Aariz ุฏุฑ ุณุงุฒ **1024x1024** ุฑุง ุจุฑุง ฺฉุงุฑุช ฺฏุฑุงูฺฉ **RTX 3070 Ti (8GB VRAM)** ู **48GB RAM** ุชูุถุญ ูโุฏูุฏ.

## ๐ฏ ูพุดโูุงุฒูุง

- โ ุฏุชุงุณุช Aariz ุฏุฑ ูพูุดู `Aariz`
- โ ฺฉุงุฑุช ฺฏุฑุงูฺฉ RTX 3070 Ti (8GB VRAM)
- โ RAM: 48GB (ุจุฑุง cache ฺฉุฑุฏู dataset)
- โ PyTorch ุจุง ูพุดุชุจุงู CUDA ูุตุจ ุดุฏู ุจุงุดุฏ

## โ๏ธ ุชูุธูุงุช ุจููู ุจุฑุง 1024x1024

### ุชูุธูุงุช ูพุดููุงุฏ:

```bash
--image_size 1024 1024
--batch_size 2                    # ฺฉุงูุด ุงูุชู ุจุฑุง ุฌููฺฏุฑ ุงุฒ OOM
--gradient_accumulation_steps 3   # Effective batch size = 6
--lr 5e-4
--epochs 100
--loss adaptive_wing
--mixed_precision                 # ุงูุฒุงู ุจุฑุง 8GB VRAM
--num_workers 2                   # ูุดุงุจู 768x768
--use_ram_cache                   # ุงุณุชูุงุฏู ุงุฒ RAM ุจุฑุง cache
```

**ูุดุฎุตุงุช:**
- **Batch Size:** 2
- **Gradient Accumulation:** 3
- **Effective Batch Size:** 6 (ูุดุงุจู 768x768)
- **VRAM Usage:** ~7-7.5GB (ุจุง margin ุงูู)
- **RAM Usage:** ~10-15GB ุจุฑุง cache (ุงุฒ 48GB ููุฌูุฏ)
- **ุฑุณฺฉ OOM:** โ ุจุณุงุฑ ฺฉู
- **ุฒูุงู ุชูุฑุจ:** 15-20 ุณุงุนุช (ุงุฒ scratch) ุง 8-12 ุณุงุนุช (fine-tuning)

## ๐พ ุงุณุชูุงุฏู ุงุฒ RAM ุจุฑุง Cache

### ฺุฑุง ุงุฒ RAM ุงุณุชูุงุฏู ฺฉููุ

1. **ุณุฑุนุช ุจุดุชุฑ**: ุฎูุงูุฏู ุงุฒ RAM ุฎู ุณุฑุนโุชุฑ ุงุฒ ูุงุฑุฏ ุงุณุช
2. **ฺฉุงูุด I/O**: CPU ฺฉูุชุฑ ููุชุธุฑ ุฎูุงูุฏู ุฏุงุฏู ูโูุงูุฏ
3. **GPU Utilization ุจูุชุฑ**: GPU ุจุดุชุฑ ุฏุฑฺฏุฑ ูโุดูุฏ

### ฺฺฏููู ฺฉุงุฑ ูโฺฉูุฏุ

```python
# ุจุง --use_ram_cache:
# 1. ุชูุงู dataset ุฏุฑ RAM load ูโุดูุฏ (ฺฉุจุงุฑ)
# 2. ุฏุฑ epochโูุง ุจุนุฏ ุงุฒ RAM ุฎูุงูุฏู ูโุดูุฏ (ุฎู ุณุฑุน)
# 3. GPU ฺฉูุชุฑ ููุชุธุฑ ุฏุงุฏู ูโูุงูุฏ
```

### ูุตุฑู RAM:

- **Train dataset**: ~800 ุชุตูุฑ ร ~12MB = ~10GB
- **Val dataset**: ~100 ุชุตูุฑ ร ~12MB = ~1.2GB
- **Total**: ~11-15GB ุงุฒ 48GB ููุฌูุฏ โ

## ๐ ูุญูู ุงุณุชูุงุฏู

### ุฑูุด 1: ุงุณุชูุงุฏู ุงุฒ Script (ูพุดููุงุฏ) โญ

```cmd
cd Aariz
train_1024x1024_rtx3070ti.bat
```

### ุฑูุด 2: ุฏุณุชูุฑ ูุณุชูู (Fine-tuning)

```cmd
python train_1024x1024.py ^
    --resume checkpoints/checkpoint_best.pth ^
    --dataset_path Aariz ^
    --model hrnet ^
    --image_size 1024 1024 ^
    --batch_size 2 ^
    --gradient_accumulation_steps 3 ^
    --lr 1e-5 ^
    --warmup_epochs 3 ^
    --epochs 100 ^
    --loss adaptive_wing ^
    --mixed_precision ^
    --num_workers 2 ^
    --use_ram_cache ^
    --save_dir checkpoints_1024x1024 ^
    --log_dir logs_1024x1024
```

### ุฑูุด 3: ุฏุณุชูุฑ ูุณุชูู (ุงุฒ scratch)

```cmd
python train_1024x1024.py ^
    --dataset_path Aariz ^
    --model hrnet ^
    --image_size 1024 1024 ^
    --batch_size 2 ^
    --gradient_accumulation_steps 3 ^
    --lr 5e-4 ^
    --warmup_epochs 5 ^
    --epochs 100 ^
    --loss adaptive_wing ^
    --mixed_precision ^
    --num_workers 2 ^
    --use_ram_cache ^
    --save_dir checkpoints_1024x1024 ^
    --log_dir logs_1024x1024
```

## ๐ ุฌุฏูู ุชูุธูุงุช

| Batch Size | Grad Accum | Effective BS | VRAM | ุฑุณฺฉ OOM | ุชูุตู |
|------------|------------|--------------|------|----------|-------|
| 2 | 3 | 6 | ~7-7.5GB | โ Safe | โญ ูพุดููุงุฏ |
| 2 | 2 | 4 | ~6.5-7GB | โ Safe | โ ูุญุงูุธูโฺฉุงุฑุงูู |
| 1 | 6 | 6 | ~6-6.5GB | โ Safe | โ ุงฺฏุฑ OOM ฺฏุฑูุชุฏ |

## ๐ Gradient Accumulation

### ฺุฑุง ุงุณุชูุงุฏู ูโฺฉููุ

- **1024x1024** ุฎู ุจุฒุฑฺฏ ุงุณุช โ batch_size=2 ุจุฑุง ุฌููฺฏุฑ ุงุฒ OOM
- ุงูุง batch_size ฺฉูฺฺฉ = ูุงูพุงุฏุงุฑ ุขููุฒุด
- **ุฑุงูโุญู**: Gradient Accumulation

### ฺฺฏููู ฺฉุงุฑ ูโฺฉูุฏุ

```
Batch 1: forward โ backward (gradient ุฐุฎุฑู ูโุดูุฏ)
Batch 2: forward โ backward (gradient ุงุถุงูู ูโุดูุฏ)
Batch 3: forward โ backward (gradient ุงุถุงูู ูโุดูุฏ)
โ optimizer.step() (update ุจุง effective batch size = 6)
```

## โ๏ธ ูฺฉุงุช ููู

1. **ุงููู ุจุงุฑ ฺฉูุฏ ุงุณุช**: ุงฺฏุฑ `--use_ram_cache` ูุนุงู ุจุงุดุฏุ ุงููู ุจุงุฑ dataset ุฑุง ุฏุฑ RAM load ูโฺฉูุฏ (~5-10 ุฏููู)

2. **Epochโูุง ุจุนุฏ ุณุฑุนโุชุฑ**: ุจุนุฏ ุงุฒ cacheุ ูุฑ epoch ุณุฑุนโุชุฑ ูโุดูุฏ

3. **ุงฺฏุฑ OOM ฺฏุฑูุชุฏ**:
   - `batch_size` ุฑุง ุจู 1 ฺฉุงูุด ุฏูุฏ
   - `gradient_accumulation_steps` ุฑุง ุจู 6 ุงูุฒุงุด ุฏูุฏ
   - `--use_ram_cache` ุฑุง ุบุฑูุนุงู ฺฉูุฏ

4. **RAM Cache**:
   - ููุท ุงฺฏุฑ RAM ฺฉุงู ุฏุงุฑุฏ (48GB) ุงุณุชูุงุฏู ฺฉูุฏ
   - ุงฺฏุฑ RAM ูุญุฏูุฏ ุงุณุชุ `--use_ram_cache` ุฑุง ุญุฐู ฺฉูุฏ

## ๐ ุณุงุฎุชุงุฑ ุฎุฑูุฌ

```
checkpoints_1024x1024/
โโโ checkpoint_best.pth      # ุจูุชุฑู ูุฏู
โโโ checkpoint_latest.pth     # ุขุฎุฑู checkpoint
โโโ checkpoint_epoch_*.pth    # Checkpoint ูุง ุฏูุฑูโุง

logs_1024x1024/
โโโ events.out.tfevents.*      # TensorBoard logs
```

## ๐ ูุงูุชูุฑูฺฏ

ุจุฑุง ูุธุงุฑุช ุจุฑ ุงุณุชูุงุฏู ุงุฒ ููุงุจุน:

```bash
# GPU
nvidia-smi -l 1

# RAM (Task Manager > Performance > Memory)
```

## โ ฺฺฉโูุณุช

- [ ] `batch_size=2` ุชูุธู ุดุฏู
- [ ] `gradient_accumulation_steps=3` ุชูุธู ุดุฏู
- [ ] `mixed_precision` ูุนุงู ุงุณุช
- [ ] `num_workers=2` ุชูุธู ุดุฏู
- [ ] `--use_ram_cache` ูุนุงู ุงุณุช (ุงฺฏุฑ RAM ฺฉุงู ุฏุงุฑุฏ)
- [ ] VRAM Usage ุฒุฑ 8GB ุงุณุช
- [ ] RAM Usage ุฒุฑ 48GB ุงุณุช

## ๐ฏ ูุชุฌู

ุจุง ุงู ุชูุธูุงุช:
- โ OOM ููโุดูุฏ
- โ ุงุฒ RAM ุจุฑุง ุณุฑุนุช ุจุดุชุฑ ุงุณุชูุงุฏู ูโุดูุฏ
- โ Effective batch size = 6 (ูุดุงุจู 768x768)
- โ ุขููุฒุด ูพุงุฏุงุฑ ู ุณุฑุน
















